{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for optimizing the pipeline hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, KFold\n",
    "from sklearn.decomposition import FastICA, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for storing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, fname):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def pickle_load(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autosklearn run with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_autoskl(X, y, feature_preprocessor, minute_run):\n",
    "    automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "            include = {\n",
    "                # Classifiers\n",
    "                'classifier': [\"decision_tree\", \"random_forest\", \"gradient_boosting\", \"liblinear_svc\", \"k_nearest_neighbors\"],\n",
    "                'feature_preprocessor': [feature_preprocessor],\n",
    "            },\n",
    "            # Inner cross validation\n",
    "            resampling_strategy=\"cv\",\n",
    "            resampling_strategy_arguments={\"folds\":5},\n",
    "\n",
    "            time_left_for_this_task=60*minute_run,\n",
    "            tmp_folder=None,\n",
    "            memory_limit=None,\n",
    "            seed=3,\n",
    "            initial_configurations_via_metalearning=0,\n",
    "\n",
    "            n_jobs = 3,\n",
    "\n",
    "            metric=autosklearn.metrics.accuracy,\n",
    "        )\n",
    "    # Run the automl model\n",
    "    automl.fit(X,y)\n",
    "    \n",
    "    # Store results\n",
    "    fname = f'./data/bayesian_fs/accuracy_{minute_run}_minutes_{feature_preprocessor}.pkl'\n",
    "    pickle_dump(automl.cv_results_, fname)\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameter grids for random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_setup_hp_grid(number_grid):\n",
    "    # Set up possible values of parameters to optimize over, follows autosklearn and assignment 2\n",
    "    params_dt = { 'criterion' : ['gini', 'entropy'],\n",
    "                'min_samples_leaf': np.linspace(1, 20, num=number_grid, dtype=int),\n",
    "                'min_samples_split': np.linspace(2, 20, num=number_grid, dtype=int) }\n",
    "\n",
    "    params_gb = {'learning_rate' : np.linspace(0.01, 1.0, num=number_grid), \n",
    "                'max_leaf_nodes' : np.linspace(3, 2047, num=number_grid, dtype=int), \n",
    "                'min_samples_leaf' : np.linspace(1, 200, num=number_grid, dtype=int),\n",
    "                'n_iter_no_change' : np.linspace(1, 20, num=number_grid, dtype=int),\n",
    "                'validation_fraction' : np.linspace(0.01, 0.4, num=number_grid)}\n",
    "\n",
    "    params_knn = {'n_neighbors' : np.linspace(1,100, num=number_grid, dtype=int),\n",
    "                'p' : [1,2],\n",
    "                'weights' : ['uniform', 'distance']}\n",
    "\n",
    "    params_log = {'C' : np.linspace(0.03125, 5, num=number_grid), ## Restricted the upper bound from 32768 to 5, to mimic autosklearn and preserve runtime\n",
    "                'tol' : np.linspace(0.00001, 0.1, num=number_grid),\n",
    "                'penalty' : ['l1', 'l2']}\n",
    "\n",
    "    params_rf = {'bootstrap' : [True, False],\n",
    "                'criterion' : ['gini', 'entropy'],\n",
    "                'min_samples_leaf': np.linspace(1, 20, num=number_grid, dtype=int), \n",
    "                'min_samples_split': np.linspace(2, 20, num=number_grid, dtype=int) }\n",
    "    \n",
    "    param_grids = [params_dt, params_gb, params_knn, params_log, params_rf]\n",
    "    return param_grids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_rand_search(X, y, feature_preprocessor, number_grid):\n",
    "    param_grids = sklearn_setup_hp_grid(number_grid)\n",
    "    # Here are our classifiers\n",
    "    classifiers = [ DecisionTreeClassifier(random_state= 5),\n",
    "                    GradientBoostingClassifier(random_state= 5),\n",
    "                    KNeighborsClassifier(),\n",
    "                    LogisticRegression(random_state= 5, solver='liblinear'),\n",
    "                    RandomForestClassifier(random_state= 5)]\n",
    "\n",
    "    classifier_names = ['decision_tree', 'gradient_boosting', 'k_nearest_neighbors',\n",
    "                        'logistic_regression', 'random_forest']\n",
    "\n",
    "    # Choose preprocessing (Use defaults for each, kept random state)\n",
    "    if feature_preprocessor == \"fast_ica\":\n",
    "        transformer = FastICA(random_state=5)\n",
    "        X = transformer.fit_transform(X)\n",
    "    elif feature_preprocessor == \"pca\":\n",
    "        transformer = PCA(random_state=5)\n",
    "        X = transformer.fit_transform(X)\n",
    "\n",
    "    # Loop for each trial\n",
    "    all_data_accuracy = {}\n",
    "    all_data_hyperparams = {}\n",
    "\n",
    "    for j, classifier in enumerate(classifiers):\n",
    "        param_grid = param_grids[j]\n",
    "        classifier_name = classifier_names[j]\n",
    "\n",
    "        inner_cv = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "        outer_cv = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "        clf = RandomizedSearchCV(classifier, param_grid, cv=inner_cv, scoring= 'accuracy', random_state= 5)\n",
    "\n",
    "        cv_result = cross_validate(clf, X=X, y=y, cv=outer_cv, return_estimator=True)\n",
    "        \n",
    "        all_data_accuracy[classifier_name] =  cv_result['test_score']\n",
    "\n",
    "        hyperparams_runs = [cv_result['estimator'][i].best_params_ for i in range(5)]\n",
    "        all_data_hyperparams[classifier_name] = hyperparams_runs\n",
    "        \n",
    "    pickle_dump(all_data_accuracy, f'./data/rs_fs/accuracy_{number_grid}_numgrid_{feature_preprocessor}.pkl')\n",
    "    pickle_dump(all_data_hyperparams, f'./data/rs_fs/hyperparameters_{number_grid}_numgrid_{feature_preprocessor}.pkl')  \n",
    "    return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the autosklearn classifiers on varying minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = \"winequality-white.csv\"\n",
    "table = pd.read_csv(fl, delimiter = \";\", header='infer')\n",
    "\n",
    "# Feature selection options\n",
    "# All features:\n",
    "no_feature_selection = [\"alcohol\", \"density\", \"chlorides\", \"volatile acidity\", \"total sulfur dioxide\", \"fixed acidity\", \"pH\",\n",
    "                        \"residual sugar\", \"sulphates\", \"citric acid\", \"free sulfur dioxide\"]\n",
    "# Selected features from first two assignments:\n",
    "feature_selection = [\"alcohol\", \"density\", \"chlorides\", \"volatile acidity\", \"total sulfur dioxide\", \"fixed acidity\", \"pH\"]\n",
    "\n",
    "# Hyperparameters for pipeline:\n",
    "hpo_methods = [\"Bayesian Optimization\", \"Randomized Search\"]\n",
    "feature_preprocessors = [ \"no_preprocessing\", \"fast_ica\", \"pca\"]\n",
    "minutes_run = [5, 15, 30, 60]\n",
    "numbers_grid = [5, 15, 50, 100]\n",
    "feature_selection_options = [no_feature_selection, feature_selection]\n",
    "\n",
    "\n",
    "# Implementing grid search to notify what hyperparameters work with which\n",
    "# Also used to show explicitly that each hyperparameter is used\n",
    "# Sklearn's grid search doesn't work as abstract as desired.\n",
    "for features in feature_selection_options:\n",
    "    X = table[features]\n",
    "    y = table.quality\n",
    "    for hpo_method in hpo_methods:\n",
    "        for feature_preprocessor in feature_preprocessors:\n",
    "            if hpo_method == \"Bayesian Optimization\":\n",
    "                # Do bayesian for each minutes_run with \n",
    "                for minute_run in minutes_run:\n",
    "                    bayesian_autoskl(X, y, feature_preprocessor, minute_run)\n",
    "                    print(f'Minute {minute_run} is done')\n",
    "            elif hpo_method == \"Randomized Search\":\n",
    "                for number_grid in numbers_grid:\n",
    "                    sklearn_rand_search(X, y, feature_preprocessor, number_grid)\n",
    "                    print(f'number {number_grid} is done')\n",
    "            else:\n",
    "                print(f'Incorrect hpo method given')\n",
    "\n",
    "            print(f'Feature preprocessor {feature_preprocessor} is done')\n",
    "        print(f'Method {hpo_method} is done')\n",
    "    print(f'Feature selection option {features} is done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>gradient_boosting</th>\n",
       "      <th>k_nearest_neighbors</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>random_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545918</td>\n",
       "      <td>0.584694</td>\n",
       "      <td>0.645918</td>\n",
       "      <td>0.524490</td>\n",
       "      <td>0.659184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558163</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.640816</td>\n",
       "      <td>0.509184</td>\n",
       "      <td>0.636735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.516327</td>\n",
       "      <td>0.629592</td>\n",
       "      <td>0.512245</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555669</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.491318</td>\n",
       "      <td>0.629213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580184</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.632278</td>\n",
       "      <td>0.492339</td>\n",
       "      <td>0.624106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision_tree  gradient_boosting  k_nearest_neighbors  logistic_regression  \\\n",
       "0       0.545918           0.584694             0.645918             0.524490   \n",
       "1       0.558163           0.614286             0.640816             0.509184   \n",
       "2       0.557143           0.516327             0.629592             0.512245   \n",
       "3       0.555669           0.494382             0.606742             0.491318   \n",
       "4       0.580184           0.494382             0.632278             0.492339   \n",
       "\n",
       "   random_forest  \n",
       "0       0.659184  \n",
       "1       0.636735  \n",
       "2       0.671429  \n",
       "3       0.629213  \n",
       "4       0.624106  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search_acc_5 = pickle_load('./data/rs/accuracy_5_numgrid_no_preprocessing.pkl')\n",
    "pd.DataFrame.from_dict(randomized_search_acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>gradient_boosting</th>\n",
       "      <th>k_nearest_neighbors</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>random_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.560204</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.697959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541837</td>\n",
       "      <td>0.583673</td>\n",
       "      <td>0.647959</td>\n",
       "      <td>0.519388</td>\n",
       "      <td>0.691837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.567347</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.706122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.542390</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.592441</td>\n",
       "      <td>0.517875</td>\n",
       "      <td>0.663943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.522983</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.609806</td>\n",
       "      <td>0.521961</td>\n",
       "      <td>0.664964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision_tree  gradient_boosting  k_nearest_neighbors  logistic_regression  \\\n",
       "0       0.560204           0.628571             0.627551             0.557143   \n",
       "1       0.541837           0.583673             0.647959             0.519388   \n",
       "2       0.567347           0.602041             0.622449             0.542857   \n",
       "3       0.542390           0.550562             0.592441             0.517875   \n",
       "4       0.522983           0.550562             0.609806             0.521961   \n",
       "\n",
       "   random_forest  \n",
       "0       0.697959  \n",
       "1       0.691837  \n",
       "2       0.706122  \n",
       "3       0.663943  \n",
       "4       0.664964  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search_acc_15 = pickle_load('./data/rs/accuracy_15_numgrid_no_preprocessing.pkl')\n",
    "pd.DataFrame.from_dict(randomized_search_acc_15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
